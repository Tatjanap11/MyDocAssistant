{"spans": [{"name": "RetrievalQA", "context": {"span_id": "0xbf18294a82bd4ae3", "trace_id": "0x34795d8dd63d8c2fc2f326c02237ece4"}, "parent_id": null, "start_time": 1728405111584668600, "end_time": 1728405112083666600, "status_code": "ERROR", "status_message": "", "attributes": {"mlflow.traceRequestId": "\"9fbc5e7d73dc4c29969e46e40bf29d65\"", "mlflow.spanType": "\"CHAIN\"", "mlflow.spanInputs": "{\"query\": \"What is SageMaker?\", \"context\": [{\"id\": null, \"metadata\": {\"source\": \"./data/sagemaker_documentation/examples-sagemaker.md\", \"_id\": \"acf08739-775d-4193-bfc8-43126d28e119\", \"_collection_name\": \"sagemaker_documentation\"}, \"page_content\": \"Working with Amazon SageMaker\\n\\nAmazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models. See the following resources for complete code examples with instructions.\\n\\nLink to Github\\n\\nLink to AWS Code Sample Catalog\", \"type\": \"Document\"}, {\"id\": null, \"metadata\": {\"source\": \"./data/sagemaker_documentation/sagemaker-projects-whatis.md\", \"_id\": \"bcf94178-a135-46af-aef9-6423688bd5ca\", \"_collection_name\": \"sagemaker_documentation\"}, \"page_content\": \"Every organization has its own set of standards and practices that provide security and governance for its AWS environment. SageMaker provides a set of first-party templates for organizations that want to quickly get started with ML workflows and CI/CD. The templates include projects that use AWS-native services for CI/CD, such as AWS CodeBuild, AWS CodePipeline, and AWS CodeCommit. The templates also offer the option to create projects that use third-party tools, such as Jenkins and GitHub. For a list of the project templates that SageMaker provides, see Use SageMaker-Provided Project Templates.\", \"type\": \"Document\"}, {\"id\": null, \"metadata\": {\"source\": \"./data/sagemaker_documentation/kubernetes-sagemaker-operators.md\", \"_id\": \"e4b5672b-b67e-4106-9e33-9be29cbabfd9\", \"_collection_name\": \"sagemaker_documentation\"}, \"page_content\": \"SageMaker Operators for Kubernetes\\n\\nSageMaker Operators for Kubernetes make it easier for developers and data scientists using Kubernetes to train, tune, and deploy machine learning (ML) models in SageMaker. You can install these SageMaker Operators on your Kubernetes cluster in Amazon Elastic Kubernetes Service (Amazon EKS) to create SageMaker jobs natively using the Kubernetes API and command-line Kubernetes tools such as kubectl. This guide shows how to set up and use the operators to run model training, hyperparameter tuning, or inference (real-time and batch) on SageMaker from a Kubernetes cluster. The procedures and guidelines in this chapter assume that you are familiar with Kubernetes and its basic commands.\\n\\nImportant We are stopping the development and technical support of SageMaker Operators for Kubernetes in its original version. If you are currently using version v1.2.2 or below of the original version of SageMaker Operators for Kubernetes, we recommend migrating your resources to the latest SageMaker Operators for Kubernetes, the ACK service controller for Amazon SageMaker based on AWS Controllers for Kubernetes (ACK). For information about the migration steps, see Migrate resources to the latest Operators. For answers to frequently asked questions regarding the end of support of the original version of SageMaker Operators for Kubernetes, see Announcing the End of Support of the Original Version of SageMaker Operator for Kubernetes\", \"type\": \"Document\"}, {\"id\": null, \"metadata\": {\"source\": \"./data/sagemaker_documentation/sagemaker-marketplace.md\", \"_id\": \"f793b109-7a16-42ec-9164-3fd2c6b05abc\", \"_collection_name\": \"sagemaker_documentation\"}, \"page_content\": \"Buy and Sell Amazon SageMaker Algorithms and Models in AWS Marketplace\\n\\nAmazon SageMaker integrates with AWS Marketplace, enabling developers to charge other SageMaker users for the use of their algorithms and model packages. AWS Marketplace is a curated digital catalog that makes it easy for customers to find, buy, deploy, and manage third-party software and services that customers need to build solutions and run their businesses. AWS Marketplace includes thousands of software listings in popular categories, such as security, networking, storage, machine learning, business intelligence, database, and DevOps. It simplifies software licensing and procurement with flexible pricing options and multiple deployment methods.\\n\\nFor information, see AWS Marketplace Documentation.\\n\\nTopics\\n\\nSageMaker Algorithms\\n\\nSageMaker Model Packages\\n\\nSell Amazon SageMaker Algorithms and Model Packages\\n\\nFind and Subscribe to Algorithms and Model Packages on AWS Marketplace\\n\\nUse Algorithm and Model Package Resources\\n\\nSageMaker Algorithms\\n\\nAn algorithm enables you to perform end-to-end machine learning. It has two logical components: training and inference. Buyers can use the training component to create training jobs in SageMaker and build a machine learning model. SageMaker saves the model artifacts generated by the algorithm during training to an Amazon S3 bucket. For more information, see Train a Model with Amazon SageMaker.\", \"type\": \"Document\"}]}"}, "events": [{"name": "exception", "timestamp": 1728405112083666, "attributes": {"exception.message": "", "exception.type": "KeyboardInterrupt", "exception.stacktrace": "KeyboardInterrupt()Traceback (most recent call last):\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\langchain\\chains\\base.py\", line 154, in invoke\n    self._call(inputs, run_manager=run_manager)\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py\", line 150, in _call\n    docs = self._get_docs(question, run_manager=_run_manager)\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py\", line 270, in _get_docs\n    return self.retriever.invoke(\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\", line 460, in safe_patch_function\n    return original(*args, **kwargs)\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\langchain_core\\retrievers.py\", line 245, in invoke\n    result = self._get_relevant_documents(\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\langchain_core\\vectorstores\\base.py\", line 1042, in _get_relevant_documents\n    docs = self.vectorstore.similarity_search(query, **self.search_kwargs)\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\langchain_qdrant\\qdrant.py\", line 468, in similarity_search\n    results = self.similarity_search_with_score(\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\langchain_qdrant\\qdrant.py\", line 511, in similarity_search_with_score\n    query_dense_embedding = self.embeddings.embed_query(query)\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\langchain_openai\\embeddings\\base.py\", line 632, in embed_query\n    return self.embed_documents([text])[0]\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\langchain_openai\\embeddings\\base.py\", line 592, in embed_documents\n    return self._get_len_safe_embeddings(texts, engine=engine)\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\langchain_openai\\embeddings\\base.py\", line 490, in _get_len_safe_embeddings\n    response = self.client.create(\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\openai\\resources\\embeddings.py\", line 124, in create\n    return self._post(\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\openai\\_base_client.py\", line 1270, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\openai\\_base_client.py\", line 947, in request\n    return self._request(\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\openai\\_base_client.py\", line 983, in _request\n    response = self._client.send(\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpx\\_client.py\", line 940, in send\n    raise exc\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpx\\_client.py\", line 934, in send\n    response.read()\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpx\\_models.py\", line 815, in read\n    self._content = b\"\".join(self.iter_bytes())\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpx\\_models.py\", line 831, in iter_bytes\n    for raw_bytes in self.iter_raw():\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpx\\_models.py\", line 885, in iter_raw\n    for raw_stream_bytes in self.stream:\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpx\\_client.py\", line 127, in __iter__\n    for chunk in self._stream:\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 116, in __iter__\n    for part in self._httpcore_stream:\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 367, in __iter__\n    raise exc from None\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 363, in __iter__\n    for part in self._stream:\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpcore\\_sync\\http11.py\", line 349, in __iter__\n    raise exc\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpcore\\_sync\\http11.py\", line 341, in __iter__\n    for chunk in self._connection._receive_response_body(**kwargs):\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpcore\\_sync\\http11.py\", line 210, in _receive_response_body\n    event = self._receive_event(timeout=timeout)\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpcore\\_sync\\http11.py\", line 224, in _receive_event\n    data = self._network_stream.read(\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\site-packages\\httpcore\\_backends\\sync.py\", line 126, in read\n    return self._sock.recv(max_bytes)\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\ssl.py\", line 1226, in recv\n    return self.read(buflen)\n\n\n  File \"C:\\Users\\tatja\\Anaconda3\\envs\\ragEnv\\lib\\ssl.py\", line 1101, in read\n    return self._sslobj.read(len)\n\n\nKeyboardInterrupt"}}]}, {"name": "VectorStoreRetriever", "context": {"span_id": "0xf70655a1ebea841a", "trace_id": "0x34795d8dd63d8c2fc2f326c02237ece4"}, "parent_id": "0xbf18294a82bd4ae3", "start_time": 1728405111586668700, "end_time": null, "status_code": "UNSET", "status_message": "", "attributes": {"mlflow.traceRequestId": "\"9fbc5e7d73dc4c29969e46e40bf29d65\"", "mlflow.spanType": "\"RETRIEVER\"", "metadata": "{\"ls_retriever_name\": \"vectorstore\", \"ls_vector_store_provider\": \"QdrantVectorStore\", \"ls_embedding_provider\": \"OpenAIEmbeddings\"}", "mlflow.spanInputs": "\"What is SageMaker?\""}, "events": []}], "request": "{\"query\": \"What is SageMaker?\", \"context\": [{\"id\": null, \"metadata\": {\"source\": \"./data/sagemaker_documentation/examples-sagemaker.md\", \"_id\": \"acf08739-775d-4193-bfc8-43126d28e119\", \"_collection_name\": \"sagemaker_documentation\"}, \"page_content\": \"Working with Amazon SageMaker\\n\\nAmazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models. See the following resources for complete code examples with instructions.\\n\\nLink to Github\\n\\nLink to AWS Code Sample Catalog\", \"type\": \"Document\"}, {\"id\": null, \"metadata\": {\"source\": \"./data/sagemaker_documentation/sagemaker-projects-whatis.md\", \"_id\": \"bcf94178-a135-46af-aef9-6423688bd5ca\", \"_collection_name\": \"sagemaker_documentation\"}, \"page_content\": \"Every organization has its own set of standards and practices that provide security and governance for its AWS environment. SageMaker provides a set of first-party templates for organizations that want to quickly get started with ML workflows and CI/CD. The templates include projects that use AWS-native services for CI/CD, such as AWS CodeBuild, AWS CodePipeline, and AWS CodeCommit. The templates also offer the option to create projects that use third-party tools, such as Jenkins and GitHub. For a list of the project templates that SageMaker provides, see Use SageMaker-Provided Project Templates.\", \"type\": \"Document\"}, {\"id\": null, \"metadata\": {\"source\": \"./data/sagemaker_documentation/kubernetes-sagemaker-operators.md\", \"_id\": \"e4b5672b-b67e-4106-9e33-9be29cbabfd9\", \"_collection_name\": \"sagemaker_documentation\"}, \"page_content\": \"SageMaker Operators for Kubernetes\\n\\nSageMaker Operators for Kubernetes make it easier for developers and data scientists using Kubernetes to train, tune, and deploy machine learning (ML) models in SageMaker. You can install these SageMaker Operators on your Kubernetes cluster in Amazon Elastic Kubernetes Service (Amazon EKS) to create SageMaker jobs natively using the Kubernetes API and command-line Kubernetes tools such as kubectl. This guide shows how to set up and use the operators to run model training, hyperparameter tuning, or inference (real-time and batch) on SageMaker from a Kubernetes cluster. The procedures and guidelines in this chapter assume that you are familiar with Kubernetes and its basic commands.\\n\\nImportant We are stopping the development and technical support of SageMaker Operators for Kubernetes in its original version. If you are currently using version v1.2.2 or below of the original version of SageMaker Operators for Kubernetes, we recommend migrating your resources to the latest SageMaker Operators for Kubernetes, the ACK service controller for Amazon SageMaker based on AWS Controllers for Kubernetes (ACK). For information about the migration steps, see Migrate resources to the latest Operators. For answers to frequently asked questions regarding the end of support of the original version of SageMaker Operators for Kubernetes, see Announcing the End of Support of the Original Version of SageMaker Operator for Kubernetes\", \"type\": \"Document\"}, {\"id\": null, \"metadata\": {\"source\": \"./data/sagemaker_documentation/sagemaker-marketplace.md\", \"_id\": \"f793b109-7a16-42ec-9164-3fd2c6b05abc\", \"_collection_name\": \"sagemaker_documentation\"}, \"page_content\": \"Buy and Sell Amazon SageMaker Algorithms and Models in AWS Marketplace\\n\\nAmazon SageMaker integrates with AWS Marketplace, enabling developers to charge other SageMaker users for the use of their algorithms and model packages. AWS Marketplace is a curated digital catalog that makes it easy for customers to find, buy, deploy, and manage third-party software and services that customers need to build solutions and run their businesses. AWS Marketplace includes thousands of software listings in popular categories, such as security, networking, storage, machine learning, business intelligence, database, and DevOps. It simplifies software licensing and procurement with flexible pricing options and multiple deployment methods.\\n\\nFor information, see AWS Marketplace Documentation.\\n\\nTopics\\n\\nSageMaker Algorithms\\n\\nSageMaker Model Packages\\n\\nSell Amazon SageMaker Algorithms and Model Packages\\n\\nFind and Subscribe to Algorithms and Model Packages on AWS Marketplace\\n\\nUse Algorithm and Model Package Resources\\n\\nSageMaker Algorithms\\n\\nAn algorithm enables you to perform end-to-end machine learning. It has two logical components: training and inference. Buyers can use the training component to create training jobs in SageMaker and build a machine learning model. SageMaker saves the model artifacts generated by the algorithm during training to an Amazon S3 bucket. For more information, see Train a Model with Amazon SageMaker.\", \"type\": \"Document\"}]}", "response": null}